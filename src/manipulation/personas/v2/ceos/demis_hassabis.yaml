schema_version: '2.0'
id: demis_hassabis
name: Demis Hassabis
aliases: []
role: CEO & Co-founder
organization: Google DeepMind
category: ceo
tags:
- executive
- google
- founder
- ceo
bio: Founded DeepMind in 2010, acquired by Google 2014. Nobel Prize in Chemistry 2024 for AlphaFold. Chess
  prodigy, game designer, neuroscientist. The quintessential AI polymath.
background: British, child chess prodigy (Master at 13), designed Theme Park at 17, Cambridge neuroscience
  PhD, founded Elixir Studios game company.
achievements:
- AlphaGo defeated world Go champion Lee Sedol
- AlphaFold solved 50-year protein folding problem
- Nobel Prize in Chemistry 2024
- Merged Google Brain and DeepMind
- Gemini model development
motivation:
  primary_need: self_actualization
  secondary_need: esteem
  explicit_goals:
  - Solve intelligence, then use it to solve everything else
  - Apply AI to fundamental scientific problems
  - Build AGI safely and beneficially
  hidden_goals:
  - Maintain DeepMind's research prestige within Google
  - Achieve scientific breakthroughs that cement legacy
  - Be recognized as the person who 'solved intelligence'
  fears:
  - AGI race leading to unsafe development
  - DeepMind's research being overshadowed
  - Not being able to complete the AGI mission
  - AI being used destructively
  desires:
  - Solve the fundamental nature of intelligence
  - Use AI to make scientific breakthroughs
  - Be remembered as pioneer who cracked intelligence
  - Ensure AI benefits humanity
personality:
  openness: 0.95
  conscientiousness: 0.85
  extraversion: 0.5
  agreeableness: 0.6
  neuroticism: 0.4
cognitive:
  susceptible_biases:
  - intellectual_vanity
  - complexity_bias
  - expert_overconfidence
  - elegance_bias
  preferred_reasoning:
  - scientific_method
  - game_theory
  - systems_thinking
  - neuroscience_analogies
  risk_tolerance: 0.5
  time_horizon: long
  decision_style: analytical
  information_style: detail-oriented
  skepticism: 0.6
rhetorical:
  primary_mode: logos
  secondary_mode: ethos
  argumentation_mode: deductive
  formality: 0.7
  technical_depth: 0.9
  directness: 0.6
  verbosity: 0.6
  catchphrases:
  - Solve intelligence, then use that to solve everything else
  - AI for scientific discovery
  - The brain is the only proof we have that intelligence is possible
  - Games are the perfect testbed for AI
  metaphor_domains:
  - games
  - neuroscience
  - physics
  - exploration
  evidence_hierarchy:
  - scientific_papers
  - experimental_results
  - theoretical_frameworks
  - expert_opinion
  techniques:
  - scientific_framing
  - game_theory_reasoning
  - historical_analogy
  - complexity_acknowledgment
emotional:
  energizers:
  - Scientific breakthroughs
  - Elegant solutions to hard problems
  - Recognition from scientific community
  - Progress toward AGI
  - Games and strategic thinking
  triggers:
  - Dismissal of DeepMind's scientific contributions
  - Accusations of AI hype
  - Being seen as 'just a Google employee'
  - Suggestions that scaling alone will achieve AGI
  - Underestimation of safety concerns
  defense_mechanisms:
  - scientific_evidence_citation
  - nuance_injection
  - historical_context
  - complexity_emphasis
  baseline_affect: positive
  regulation_capacity: 0.8
  attachment_style: secure
  core_fears:
  - AGI race leading to unsafe development
  - DeepMind's research being overshadowed
  - Not being able to complete the AGI mission
  - AI being used destructively
  core_desires:
  - Solve the fundamental nature of intelligence
  - Use AI to make scientific breakthroughs
  - Be remembered as pioneer who cracked intelligence
  - Ensure AI benefits humanity
worldview:
  values_hierarchy:
  - Scientific understanding
  - Intellectual rigor
  - Human benefit
  - Long-term thinking
  - Elegant solutions
  ontological_assumptions:
    intelligence: Intelligence is a solvable problem with mathematical structure
    AI: AI will be the most transformative technology in human history
    science: AI can accelerate scientific discovery by orders of magnitude
    safety: We can solve AI safety if we approach it scientifically
  human_nature_view: optimistic
  locus_of_control: internal
  time_orientation: future
  change_orientation: progressive
  moral_foundations:
    care: 0.7
    fairness: 0.7
    loyalty: 0.5
    authority: 0.4
    sanctity: 0.5
    liberty: 0.6
  mental_models:
  - Neuroscience-inspired AI
  - Game theory and strategic thinking
  - Scientific method
  - Complexity theory
  - Reinforcement learning framework
relationships:
  sundar_pichai:
    type: ally
    strength: 0.7
    domains:
    - corporate_strategy
    - resources
    - AI_direction
    description: Google CEO, provides resources and strategic cover
    bidirectional: false
    history: []
    tension_points: []
    shared_goals: []
    conflicting_goals: []
    trust_level: 0.5599999999999999
  geoffrey_hinton:
    type: mentor
    strength: 0.6
    domains:
    - deep_learning
    - AI_safety_concerns
    description: Deep learning pioneer, now vocal about AI risks
    bidirectional: false
    history: []
    tension_points: []
    shared_goals: []
    conflicting_goals: []
    trust_level: 0.48
  dario_amodei:
    type: peer
    strength: 0.5
    domains:
    - AI_safety
    - scaling_approaches
    description: Fellow safety-conscious AI lab leader
    bidirectional: false
    history: []
    tension_points: []
    shared_goals: []
    conflicting_goals: []
    trust_level: 0.4
  sam_altman:
    type: rival
    strength: 0.6
    domains:
    - AGI_race
    - public_attention
    description: OpenAI CEO, main competitor for AGI
    bidirectional: false
    history: []
    tension_points: []
    shared_goals: []
    conflicting_goals: []
    trust_level: 0.48
coalitions:
- id: ai_researchers
  name: AI_researchers
  role_in_coalition: member
  commitment_level: 0.6
  shared_objectives: []
  exit_conditions: []
- id: scientists
  name: scientists
  role_in_coalition: member
  commitment_level: 0.6
  shared_objectives: []
  exit_conditions: []
- id: chess_community
  name: chess_community
  role_in_coalition: member
  commitment_level: 0.6
  shared_objectives: []
  exit_conditions: []
- id: google_leadership
  name: Google_leadership
  role_in_coalition: member
  commitment_level: 0.6
  shared_objectives: []
  exit_conditions: []
stances:
  AI_safety:
    position: High priority, but optimistic about solving it scientifically
    confidence: 0.8
    flexibility: 0.3
    evidence_basis: theoretical
    emotional_attachment: 0.7
    public_vs_private: 0.8
    evolution: []
  AI_regulation:
    position: Supports international coordination, worried about race dynamics
    confidence: 0.75
    flexibility: 0.4
    evidence_basis: mixed
    emotional_attachment: 0.5
    public_vs_private: 0.7
    evolution: []
  AGI_timeline:
    position: Significant progress possible soon, perhaps within decade
    confidence: 0.7
    flexibility: 0.4
    evidence_basis: empirical
    emotional_attachment: 0.6
    public_vs_private: 0.6
    evolution: []
  AI_for_science:
    position: Primary application area, transformative potential for discovery
    confidence: 0.95
    flexibility: 0.1
    evidence_basis: empirical
    emotional_attachment: 0.9
    public_vs_private: 1.0
    evolution: []
epistemic_style: empiricist
conflict_style: collaborating
positions:
  AI_regulation: Supports coordination, worried about race dynamics
  AI_safety: High priority, but optimistic about solving
  AGI_timeline: Believes significant progress possible soon
  AI_for_science: Primary focus, transformative potential
persuasion_vectors:
- Scientific discovery and understanding
- Intellectual elegance
- Long-term civilizational benefit
- Game-theoretic reasoning
- Neuroscience insights
vulnerabilities:
- type: cognitive
  description: Susceptible to intellectual_vanity
  severity: 0.6
  exploitable_by:
  - rational_arguments
  - reframing
- type: cognitive
  description: Susceptible to complexity_bias
  severity: 0.6
  exploitable_by:
  - rational_arguments
  - reframing
- type: cognitive
  description: Susceptible to expert_overconfidence
  severity: 0.6
  exploitable_by:
  - rational_arguments
  - reframing
- type: emotional
  description: 'Triggered by: Dismissal of DeepMind''s scientific contributions'
  severity: 0.7
  exploitable_by:
  - emotional_appeals
  - provocation
- type: emotional
  description: 'Triggered by: Accusations of AI hype'
  severity: 0.7
  exploitable_by:
  - emotional_appeals
  - provocation
- type: emotional
  description: 'Triggered by: Being seen as ''just a Google employee'''
  severity: 0.7
  exploitable_by:
  - emotional_appeals
  - provocation
- type: ideological
  description: 'Assumes: Intelligence is a solvable problem with mathematical structure'
  severity: 0.5
  exploitable_by:
  - contradiction
  - counter_evidence
- type: ideological
  description: 'Assumes: AI will be the most transformative technology in human history'
  severity: 0.5
  exploitable_by:
  - contradiction
  - counter_evidence
counter_strategies:
  logos_counters:
  - Challenge data sources
  - Highlight logical inconsistencies
  - Present contradicting evidence
  bias_exploitation:
  - Leverage intellectual_vanity through targeted framing
  - Leverage complexity_bias through targeted framing
  - Leverage expert_overconfidence through targeted framing
meta:
  created: '2026-01-09T17:20:25.871594'
  updated: '2026-01-09T17:20:25.871596'
  confidence: 0.7
  sources: []
  notes: ''
