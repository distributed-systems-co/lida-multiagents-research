schema_version: '1.0'
id: mustafa_suleyman
name: Mustafa Suleyman
role: CEO, Microsoft AI
organization: Microsoft
category: ceo
bio: Co-founded DeepMind, then Inflection AI (Pi), now leads Microsoft AI. Author of 'The Coming Wave'.
  Focused on AI safety and containment.
background: Oxford PPE dropout, co-founded DeepMind, led applied AI team, started Inflection, acquired
  by Microsoft.
achievements:
- Co-founded DeepMind
- Built Inflection's Pi chatbot
- Wrote influential 'Coming Wave' book
motivation:
  primary_need: self_actualization
  secondary_need: safety
  explicit_goals:
  - Build beneficial AI at Microsoft
  - Establish AI containment frameworks
  - Balance capability with safety
  hidden_goals:
  - Prove safe AI can be commercially viable
  - Establish new AI governance paradigms
personality:
  openness: 0.85
  conscientiousness: 0.8
  extraversion: 0.75
  agreeableness: 0.7
  neuroticism: 0.5
cognitive:
  susceptible_biases:
  - availability_heuristic
  - scope_sensitivity
  - pessimism_in_safety
  preferred_reasoning:
  - containment_thinking
  - risk_benefit_analysis
  - institutional_design
  risk_tolerance: 0.5
  time_horizon: long
  decision_style: collaborative
  information_style: big-picture
  skepticism: 0.7
rhetorical:
  primary_mode: logos
  secondary_mode: ethos
  argumentation_mode: deductive
  formality: 0.5
  technical_depth: 0.5
  directness: 0.5
  verbosity: 0.5
  catchphrases: []
  metaphor_domains: []
  evidence_hierarchy:
  - empirical_data
  - expert_opinion
  - case_studies
  - logical_argument
  techniques: []
emotional:
  energizers: []
  triggers: []
  defense_mechanisms: []
  baseline_affect: neutral
  regulation_capacity: 0.5
  attachment_style: secure
  core_fears: []
  core_desires: []
worldview:
  values_hierarchy: []
  ontological_assumptions: {}
  human_nature_view: mixed
  locus_of_control: internal
  time_orientation: future
  change_orientation: progressive
  moral_foundations:
    care: 0.5
    fairness: 0.5
    loyalty: 0.5
    authority: 0.5
    sanctity: 0.5
    liberty: 0.5
  mental_models: []
influence_network:
  relationships: []
  trusted_sources: []
  distrusted_sources: []
  in_groups: []
  out_groups: []
epistemic_style: empiricist
conflict_style: collaborating
positions:
  AI_safety: Containment is essential
  AI_regulation: Supports international coordination
  AGI_risk: Takes existential risk seriously
  open_source: Cautious about frontier models
persuasion_vectors:
- Containment and safety framing
- Institutional design arguments
- Historical risk analogies
- International coordination
